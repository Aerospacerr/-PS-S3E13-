{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-24T15:57:14.672058Z","iopub.execute_input":"2023-04-24T15:57:14.672475Z","iopub.status.idle":"2023-04-24T15:57:14.682738Z","shell.execute_reply.started":"2023-04-24T15:57:14.672439Z","shell.execute_reply":"2023-04-24T15:57:14.681277Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e13/sample_submission.csv\n/kaggle/input/playground-series-s3e13/train.csv\n/kaggle/input/playground-series-s3e13/test.csv\n/kaggle/input/vector-borne-disease-prediction/testt.csv\n/kaggle/input/vector-borne-disease-prediction/trainn.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nfrom copy import deepcopy\nfrom functools import partial\nfrom itertools import combinations\nimport random\nimport gc\n\n# Import sklearn classes for model selection, cross validation, and performance evaluation\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, log_loss\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nfrom category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder, CatBoostEncoder\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.decomposition import PCA, NMF\nfrom umap import UMAP\nfrom sklearn.manifold import TSNE\n\n# Import libraries for Hypertuning\nimport optuna\n\n# Import libraries for gradient boosting\nimport xgboost as xgb\nimport lightgbm as lgb\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom sklearn.svm import NuSVC, SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nfrom catboost import Pool\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Useful line of code to set the display option so we could see all the columns in pd dataframe\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\npd.set_option('display.width', 500)\npd.set_option('display.expand_frame_repr', False)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T15:57:14.684959Z","iopub.execute_input":"2023-04-24T15:57:14.685338Z","iopub.status.idle":"2023-04-24T15:57:14.700544Z","shell.execute_reply.started":"2023-04-24T15:57:14.685300Z","shell.execute_reply":"2023-04-24T15:57:14.699255Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"PATH_ORIGIN = '/kaggle/input/vector-borne-disease-prediction/trainn.csv'\nPATH_TRAIN = '/kaggle/input/playground-series-s3e13/train.csv'\nPATH_TEST = '/kaggle/input/playground-series-s3e13/test.csv'\nPATH_SUB = '/kaggle/input/playground-series-s3e13/sample_submission.csv'\n\norigin = pd.read_csv(PATH_ORIGIN)\ntrain =  pd.read_csv(PATH_TRAIN).drop(columns='id')\ntest =   pd.read_csv(PATH_TEST).drop(columns='id')\n\ntrain['is_generated'] = 1\ntest['is_generated'] = 1\norigin['is_generated'] = 0\n\norigin.prognosis = origin.prognosis.str.replace(' ', '_')\n\nfull_train = pd.concat([train, origin], axis=0).reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T15:57:14.702277Z","iopub.execute_input":"2023-04-24T15:57:14.703128Z","iopub.status.idle":"2023-04-24T15:57:14.744628Z","shell.execute_reply.started":"2023-04-24T15:57:14.703077Z","shell.execute_reply":"2023-04-24T15:57:14.743245Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(f'[INFO] Shapes:'\n      f'\\n origin: {origin.shape}'\n      f'\\n train: {train.shape}'\n      f'\\n test: {test.shape}\\n')\n\nprint(f'[INFO] Any missing values:'\n      f'\\n origin: {origin.isna().any().any()}'\n      f'\\n train: {train.isna().any().any()}'\n      f'\\n test: {test.isna().any().any()}')","metadata":{"execution":{"iopub.status.busy":"2023-04-24T15:57:14.746063Z","iopub.execute_input":"2023-04-24T15:57:14.746435Z","iopub.status.idle":"2023-04-24T15:57:14.757686Z","shell.execute_reply.started":"2023-04-24T15:57:14.746400Z","shell.execute_reply":"2023-04-24T15:57:14.756394Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[INFO] Shapes:\n origin: (252, 66)\n train: (707, 66)\n test: (303, 65)\n\n[INFO] Any missing values:\n origin: False\n train: False\n test: False\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dictionary mapping each disease name to a corresponding integer value\ntarget_map = {\n    'Lyme_disease': 0,\n    'Tungiasis': 1,\n    'Zika': 2,\n    'Rift_Valley_fever': 3,\n    'West_Nile_fever': 4,\n    'Malaria': 5,\n    'Chikungunya': 6,\n    'Plague': 7,\n    'Dengue': 8,\n    'Yellow_Fever': 9,\n    'Japanese_encephalitis': 10\n}\nswapped_map = {v: k for k, v in target_map.items()}\nfull_train['prognosis'] = full_train['prognosis'].replace(target_map).astype(int)\n\n# Concatenate train and original dataframes, and prepare train and test sets\nX_train = full_train.drop(['prognosis'], axis=1).reset_index(drop=True).astype(int)\ny_train = full_train['prognosis'].reset_index(drop=True)\nX_test = test.reset_index(drop=True).astype(int)\nX_train_ori, X_test_ori = X_train.copy(), X_test.copy()\n\nprint(\"\")\nprint(f\"X_train shape :{X_train.shape}\")\nprint(f\"y_train shape :{y_train.shape}\")\nprint(f\"X_test shape :{X_test.shape}\")\n\n# Delete the train and test dataframes to free up memory\ndel train, test, full_train, origin\n\nX_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T15:57:14.761327Z","iopub.execute_input":"2023-04-24T15:57:14.761825Z","iopub.status.idle":"2023-04-24T15:57:14.813311Z","shell.execute_reply.started":"2023-04-24T15:57:14.761774Z","shell.execute_reply":"2023-04-24T15:57:14.811845Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"\nX_train shape :(959, 65)\ny_train shape :(959,)\nX_test shape :(303, 65)\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain  vomiting  rash  diarrhea  hypotension  pleural_effusion  ascites  gastro_bleeding  swelling  nausea  chills  myalgia  digestion_trouble  fatigue  skin_lesions  stomach_pain  orbital_pain  neck_pain  weakness  back_pain  weight_loss  gum_bleed  jaundice  coma  diziness  inflammation  red_eyes  loss_of_appetite  urination_loss  slow_heart_rate  abdominal_pain  light_sensitivity  yellow_skin  yellow_eyes  facial_distortion  microcephaly  rigor  bitter_tongue  convulsion  anemia  cocacola_urine  hypoglycemia  prostraction  hyperpyrexia  stiff_neck  irritability  confusion  tremor  paralysis  lymph_swells  breathing_restriction  toe_inflammation  finger_inflammation  lips_irritation  itchiness  ulcers  toenail_loss  speech_problem  bullseye_rash  is_generated\n0             1         1            0           1            1           1         1     0         1            1                 1        1                0         0       1       1        0                  0        1             0             1             0          1         1          1            1          1         1     1         0             0         1                 0               0                0               0                  1            0            0                  0             0      0              1           0       1               0             1             0             0           0             0          1       0          1             0                      0                 0                    0                0          0       0             0               0              0             1\n1             0         0            0           0            0           0         1     0         1            0                 1        0                1         0       1       0        0                  0        0             1             0             0          0         0          0            0          0         0     0         0             0         0                 0               0                0               0                  0            0            0                  0             0      0              0           0       0               0             0             0             0           0             0          0       0          0             0                      0                 0                    0                0          0       0             0               0              0             1\n2             0         1            1           1            0           1         1     1         1            1                 1        1                1         1       1       1        1                  0        1             1             1             1          1         1          1            1          1         1     0         0             1         1                 1               1                0               1                  0            1            1                  1             0      1              1           1       1               0             1             0             0           0             1          1       1          1             1                      1                 1                    1                1          1       0             1               1              1             1\n3             0         0            1           1            1           1         0     1         0            1                 1        0                0         1       1       1        0                  1        1             1             1             1          0         1          0            0          1         1     1         1             1         1                 1               0                0               0                  1            1            0                  1             0      0              0           0       1               0             1             0             0           0             0          0       0          0             0                      0                 0                    0                0          0       0             0               0              0             1\n4             0         0            0           0            0           0         0     0         1            0                 0        0                0         0       0       0        0                  0        0             0             0             0          0         0          0            0          0         0     0         1             0         0                 0               0                0               0                  0            0            0                  0             0      0              0           0       0               0             0             0             0           0             0          0       0          0             0                      0                 1                    0                0          1       1             1               0              0             1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sudden_fever</th>\n      <th>headache</th>\n      <th>mouth_bleed</th>\n      <th>nose_bleed</th>\n      <th>muscle_pain</th>\n      <th>joint_pain</th>\n      <th>vomiting</th>\n      <th>rash</th>\n      <th>diarrhea</th>\n      <th>hypotension</th>\n      <th>pleural_effusion</th>\n      <th>ascites</th>\n      <th>gastro_bleeding</th>\n      <th>swelling</th>\n      <th>nausea</th>\n      <th>chills</th>\n      <th>myalgia</th>\n      <th>digestion_trouble</th>\n      <th>fatigue</th>\n      <th>skin_lesions</th>\n      <th>stomach_pain</th>\n      <th>orbital_pain</th>\n      <th>neck_pain</th>\n      <th>weakness</th>\n      <th>back_pain</th>\n      <th>weight_loss</th>\n      <th>gum_bleed</th>\n      <th>jaundice</th>\n      <th>coma</th>\n      <th>diziness</th>\n      <th>inflammation</th>\n      <th>red_eyes</th>\n      <th>loss_of_appetite</th>\n      <th>urination_loss</th>\n      <th>slow_heart_rate</th>\n      <th>abdominal_pain</th>\n      <th>light_sensitivity</th>\n      <th>yellow_skin</th>\n      <th>yellow_eyes</th>\n      <th>facial_distortion</th>\n      <th>microcephaly</th>\n      <th>rigor</th>\n      <th>bitter_tongue</th>\n      <th>convulsion</th>\n      <th>anemia</th>\n      <th>cocacola_urine</th>\n      <th>hypoglycemia</th>\n      <th>prostraction</th>\n      <th>hyperpyrexia</th>\n      <th>stiff_neck</th>\n      <th>irritability</th>\n      <th>confusion</th>\n      <th>tremor</th>\n      <th>paralysis</th>\n      <th>lymph_swells</th>\n      <th>breathing_restriction</th>\n      <th>toe_inflammation</th>\n      <th>finger_inflammation</th>\n      <th>lips_irritation</th>\n      <th>itchiness</th>\n      <th>ulcers</th>\n      <th>toenail_loss</th>\n      <th>speech_problem</th>\n      <th>bullseye_rash</th>\n      <th>is_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class Validation:\n    def __init__(self, kfold=True, n_splits=5):\n        self.n_splits = n_splits\n        self.kfold = kfold\n\n    def split_data(self, X, y, random_state_list):\n        if self.kfold:\n            for random_state in random_state_list:\n                kf = StratifiedKFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n                for train_index, val_index in kf.split(X, y):\n                    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n                    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n                    yield X_train, X_val, y_train, y_val\n        else:\n            raise ValueError(f\"Invalid kfold: Must be True\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifiers:\n    def __init__(self, n_estimators=200, device=\"gpu\", random_state=17):\n        self.n_estimators = n_estimators\n        self.device = device\n        self.random_state = random_state\n        self.models = self._define_model()\n        self.len_models = len(self.models)\n        \n    def _define_model(self):\n        \n        xgb_params = {\n            'n_estimators': self.n_estimators,\n            'learning_rate': 0.01,\n            'max_depth': 10,\n            'subsample': 0.7,\n            'colsample_bytree': 0.1,\n            'n_jobs': -1,\n            'eval_metric': 'mlogloss',\n            'objective': 'multi:softprob',\n            'tree_method': 'hist',\n            'verbosity': 0,\n            'random_state': self.random_state,\n        }\n        if self.device == 'gpu':\n            xgb_params['tree_method'] = 'gpu_hist'\n            xgb_params['predictor'] = 'gpu_predictor'\n        \n        lgb_params = {\n            'n_estimators': self.n_estimators,\n            'max_depth': 6,\n            'learning_rate': 0.05,\n            'subsample': 0.20,\n            'colsample_bytree': 0.5,\n            'reg_alpha': 0.25,\n            'reg_lambda': 5e-08,\n            'objective': 'multiclass',\n            'metric': 'multi_logloss',\n            'boosting_type': 'gbdt',\n            'device': self.device,\n            'random_state': self.random_state\n        }\n                \n        cb_params = {\n            'iterations': self.n_estimators,\n            'depth': 6,\n            'learning_rate': 0.1,\n            'l2_leaf_reg': 0.7,\n            'random_strength': 0.2,\n            'max_bin': 200,\n            'od_wait': 65,\n            'one_hot_max_size': 70,\n            'grow_policy': 'Depthwise',\n            'bootstrap_type': 'Bayesian',\n            'od_type': 'Iter',\n            'eval_metric': 'MultiClass',\n            'loss_function': 'MultiClass',\n            'task_type': self.device.upper(),\n            'random_state': self.random_state\n        }\n                \n        models = {\n            'svc': SVC(gamma=\"auto\", probability=True, random_state=self.random_state),\n            'xgb': xgb.XGBClassifier(**xgb_params),\n            'lgb': lgb.LGBMClassifier(**lgb_params),\n            'cat': CatBoostClassifier(**cb_params),\n#             'brf': BalancedRandomForestClassifier(n_estimators=2000, n_jobs=-1, random_state=self.random_state),\n#             'rf': RandomForestClassifier(n_estimators=1000, random_state=self.random_state),\n#             'knn': KNeighborsClassifier(),\n#             'mlp': MLPClassifier(random_state=self.random_state, max_iter=1000),\n#             'logreg':LogisticRegression(random_state=self.random_state)\n        }\n        \n        return models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Prepare Model \n\nkfold = True\nn_splits = 1 if not kfold else 5\nrandom_state = 17\nrandom_state_list = [17]\nn_estimators = 100\nearly_stopping_rounds = 200\nverbose = False\ndevice = 'cpu'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CV = Validation(kfold=kfold, n_splits=n_splits)\n\n# Initialize an array for storing test predictions\ntest_predss = np.zeros((X_test.shape[0], len(y_train.unique())))\nensemble_score = []\nweights = []\ntrained_models = {'xgb':[], 'lgb':[], 'cat':[], 'rf':[]}\nrank_df = pd.DataFrame(columns=swapped_map.keys(), index=X_test.index).fillna(0)\n\n    \nfor i, (X_train_, X_val, y_train_, y_val) in enumerate(CV.split_data(X_train, y_train, random_state_list=random_state_list)):\n    n = i % n_splits\n    m = i // n_splits\n            \n    # Get a set of Regressor models\n    classifier = Classifier(n_estimators, device, random_state)\n    models = classifier.models\n    \n    # Initialize lists to store oof and test predictions for each base model\n    oof_preds = []\n    test_preds = []\n    \n    # Loop over each base model and fit it to the training data, evaluate on validation data, and store predictions\n    for name, model in models.items():\n        if name in ['xgb', 'lgb','cat']:\n            model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n        elif name in ['svc']:\n            parameters = {'kernel':('linear', 'rbf','sigmoid','poly'), 'C':[1, 10],'class_weight':['balanced',None],\n                         'decision_function_shape':['ovo','ovr']}\n            gs = GridSearchCV(model,parameters,n_jobs=-1)\n            gs.fit(X_train_, y_train_)\n            model = gs.best_estimator_\n#             print(f'Best params at FOLD_{n}: {gs.best_params_}')\n        else:\n            model.fit(X_train_, y_train_)\n        if name in trained_models.keys():\n            trained_models[f'{name}'].append(deepcopy(model))\n        \n        test_pred = model.predict_proba(X_test)\n        y_val_pred = model.predict_proba(X_val)\n\n        score = log_loss(y_val, y_val_pred)\n        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] Logloss score: {score:.5f}')\n        \n        oof_preds.append(y_val_pred)\n        test_preds.append(test_pred)\n    \n    # Use Optuna to find the best ensemble weights\n    optweights = OptunaWeights(random_state=random_state)\n    y_val_pred = optweights.fit_predict(y_val.values, oof_preds)\n    \n    score = log_loss(y_val, y_val_pred)\n    print(f'Ensemble [FOLD-{n} SEED-{random_state_list[m]}] Logloss score {score:.5f}')\n    ensemble_score.append(score)\n    weights.append(optweights.weights)\n    \n    # Predict to X_test by the best ensemble weights\n    _test_preds = optweights.predict(test_preds)\n    test_predss += _test_preds / (n_splits * len(random_state_list))\n    \n    # Rank Prediction\n    for i in range(_test_preds.shape[0]):\n        arr = _test_preds[i]\n        sorted_indices = np.argsort(arr)\n        for k, p in zip(range(1, 10), [9, 8, 7, 6, 5, 4, 3, 2, 1]):\n            second_largest_index = sorted_indices[-k]\n            rank_df.loc[i, second_largest_index] += p\n    \n    gc.collect()","metadata":{},"execution_count":null,"outputs":[]}]}