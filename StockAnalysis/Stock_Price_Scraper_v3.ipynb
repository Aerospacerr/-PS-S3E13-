{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1g-Ktm25aBySjNjQ2_Urdahw9CezanBDv",
      "authorship_tag": "ABX9TyN3AyyhbO+/c+T4+EypEMhl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aerospacerr/-PS-S3E13-/blob/main/StockAnalysis/Stock_Price_Scraper_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization and Imports"
      ],
      "metadata": {
        "id": "qo74hyAEeKML"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_OOrC1EiYYb-",
        "outputId": "e6d140c9-a080-4edc-be0e-05aa808502b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [861 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,552 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,217 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,396 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,421 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,884 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,785 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,115 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,130 kB]\n",
            "Fetched 24.8 MB in 11s (2,340 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "62 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.16).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "--2024-08-01 13:39:56--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.81, 91.189.91.82, 91.189.91.83, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-01 13:39:56 (361 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb’ saved [3708/3708]\n",
            "\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "(Reading database ... 123588 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-08-01 13:39:58--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 209.85.145.190, 209.85.145.136, 209.85.145.93, ...\n",
            "Connecting to dl.google.com (dl.google.com)|209.85.145.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109450340 (104M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 104.38M   228MB/s    in 0.5s    \n",
            "\n",
            "2024-08-01 13:39:58 (228 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [109450340/109450340]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 123592 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (127.0.6533.88-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-08-01 13:40:15--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/chrome-for-testing-public/118.0.5993.70/linux64/chromedriver-linux64.zip [following]\n",
            "--2024-08-01 13:40:15--  https://storage.googleapis.com/chrome-for-testing-public/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.126.207, 74.125.132.207, 74.125.201.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.126.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8269742 (7.9M) [application/zip]\n",
            "Saving to: ‘/tmp/chromedriver-linux64.zip’\n",
            "\n",
            "chromedriver-linux6 100%[===================>]   7.89M  42.4MB/s    in 0.2s    \n",
            "\n",
            "2024-08-01 13:40:16 (42.4 MB/s) - ‘/tmp/chromedriver-linux64.zip’ saved [8269742/8269742]\n",
            "\n",
            "Archive:  /tmp/chromedriver-linux64.zip\n",
            "  inflating: /tmp/chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: /tmp/chromedriver-linux64/chromedriver  \n",
            "Collecting selenium\n",
            "  Downloading selenium-4.23.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting chromedriver_autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.7.4)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (24.1)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading selenium-4.23.1-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Downloading trio-0.26.0-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.7/475.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, chromedriver_autoinstaller, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed chromedriver_autoinstaller-0.6.4 h11-0.14.0 outcome-1.3.0.post0 selenium-4.23.1 trio-0.26.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.41)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.2.2)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "# ### Initialization and Imports\n",
        "# Update the system\n",
        "!sudo apt -y update\n",
        "\n",
        "# Install required packages\n",
        "!sudo apt install -y wget curl unzip\n",
        "\n",
        "# Download and install libu2f-udev dependency for Chrome\n",
        "!wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "!dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "\n",
        "# Download and install Google Chrome\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "# Download and install ChromeDriver\n",
        "!wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "!unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "!chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "!mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "\n",
        "# Install selenium and chromedriver_autoinstaller\n",
        "!pip install selenium chromedriver_autoinstaller\n",
        "!pip install yfinance\n",
        "\n",
        "from IPython.display import clear_output\n",
        "#clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import sys\n",
        "import time\n",
        "from urllib.parse import quote\n",
        "import re\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "import yfinance as yf\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "6FK33bcoyEbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add chromedriver to system path\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "# Configure Chrome options for headless browsing\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # Run Chrome in headless mode\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "# Install ChromeDriver automatically\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "# Initialize Chrome driver\n",
        "driver = webdriver.Chrome(options=chrome_options)"
      ],
      "metadata": {
        "id": "2MM7HydXyAG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "import time\n",
        "from urllib.parse import quote\n",
        "import re\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "import yfinance as yf\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless') # this is must\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chromedriver_autoinstaller.install()\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)"
      ],
      "metadata": {
        "id": "T_fV0cMpZBsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scraping\n",
        "trade_data = []"
      ],
      "metadata": {
        "id": "T6W81StQZWxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "s85KwyrEeaov",
        "outputId": "97488809-8c21-4b78-dc3a-9458c7bdf43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'stopp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-29799910553f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stopp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "JKFy3bfM7Hpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Scraping"
      ],
      "metadata": {
        "id": "F1KkqQjseGrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "driver.get('https://www.quiverquant.com/politicians/')\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "politician_links = []\n",
        "\n",
        "for politician_link in soup.find_all('a', attrs={'class': 'flex-row-center'}):\n",
        "    politician_links.append('https://www.quiverquant.com/' + quote(politician_link.get('href').replace('../', '')))\n",
        "\n",
        "print(f'Found {len(politician_links)} politicians')\n",
        "#print(f'First politician: {politician_links[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-2EZCcsOnKh",
        "outputId": "76fe5a28-6362-4523-a9c6-89e0fd30ceb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 politicians\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver.get('https://www.quiverquant.com/congresstrading/')\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "politician_links = []\n",
        "\n",
        "for politician_link in soup.find_all('a', attrs={'class': 'flex-row-center'}):\n",
        "    politician_links.append('https://www.quiverquant.com/' + quote(politician_link.get('href').replace('../', '')))\n",
        "\n",
        "print(f'Found {len(politician_links)} politicians')\n",
        "print(f'First politician: {politician_links[0]}')"
      ],
      "metadata": {
        "id": "3rzdEldhZXlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840798b8-aafd-4862-ecda-24f428c67953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 88 politicians\n",
            "First politician: https://www.quiverquant.com/congresstrading/politician/Josh%20Gottheimer-G000583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YdEpBq6NJ_p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = tqdm(politician_links)\n",
        "\n",
        "for politician_link in pbar:\n",
        "    while True:\n",
        "        driver.get(politician_link)\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "        script_tag = soup.find('script', string=re.compile('let tradeData ='))\n",
        "\n",
        "        try:\n",
        "            script_content = script_tag.string\n",
        "            pbar.set_description(f'Loaded {politician_link}')\n",
        "            break\n",
        "        except:\n",
        "            pbar.set_description(f'Failed to load {politician_link}. Retrying in 10 seconds...')\n",
        "            time.sleep(10)\n",
        "\n",
        "    trade_data_match = re.search(r'let tradeData = (\\[.*?\\]);', script_content, re.DOTALL)\n",
        "    trade_data_json = trade_data_match.group(1)\n",
        "\n",
        "    trade_data_by_politician = json.loads(trade_data_json)\n",
        "\n",
        "    for td in trade_data_by_politician:\n",
        "        trade_data.append(\n",
        "            {\n",
        "                'Politician Profile': politician_link,\n",
        "                'Stock Ticker': td[0],\n",
        "                'Transaction': td[1],\n",
        "                'Disclosed': td[2],\n",
        "                'Traded': td[3],\n",
        "                'Description': td[4],\n",
        "                'Politician': td[6],\n",
        "                'House Information': td[7],\n",
        "                'Stock': td[8],\n",
        "                'Amount Range': td[10],\n",
        "                'Industry': td[13],\n",
        "                'Amount': td[14]\n",
        "            }\n",
        "        )\n",
        "\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "YzdBRdDIa9Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Exploration"
      ],
      "metadata": {
        "id": "6xuZ7hxUeDmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OaXubT7xcAO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path_yahoo = \"/content/drive/MyDrive/Upwork/Stock Data Analysis/all_stock_data.csv\"\n",
        "transactions_yahoo = pd.read_csv(file_path_yahoo)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "transactions_yahoo.sample(50)"
      ],
      "metadata": {
        "id": "eHRE4tgDCOGb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/Upwork/Stock Data Analysis/transaction_scraped.csv'\n",
        "transactions = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "transactions.sample(50)"
      ],
      "metadata": {
        "id": "WxRVD8ozfL9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions.isnull().sum()"
      ],
      "metadata": {
        "id": "OHfQMKUJrvXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(transactions)\n",
        "\n",
        "df = df.drop(columns=['Politician Profile', 'Disclosed', 'Description', 'House Information', 'Stock', 'Industry'])\n",
        "\n",
        "df['Traded'] = pd.to_datetime(df['Traded'])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ExLKbNdIb--X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "B5KKnFPVsIIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "eECDuePrrQj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "nukzK8p9GjBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values before using str.contains\n",
        "df[df['Stock Ticker'].notna() & df['Stock Ticker'].str.contains('\\.')].nunique()"
      ],
      "metadata": {
        "id": "MWltmiPuGT7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: df.head() with stock ticker = (if any . in stock ticker)\n",
        "\n",
        "df[df['Stock Ticker'].str.contains('\\.')].head()\n"
      ],
      "metadata": {
        "id": "x0HpYFsZGBxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "data = yf.download(\"AAPL\", start=\"2020-01-01\", end=\"2021-01-01\")[['Close']]\n",
        "\n",
        "# View the first few rows of the Close data\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Yd2FbutsEi_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "tickers = [\"AAPL\", \"MSFT\", \"GOOG\"]  # Replace with your set of tickers\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2021-01-01\"\n",
        "\n",
        "close_data = {}\n",
        "for ticker in tickers:\n",
        "    data = yf.download(ticker, start=start_date, end=end_date)[['Close']]\n",
        "    close_data[ticker] = data\n",
        "\n",
        "# Access the Close data for a specific ticker\n",
        "close_data"
      ],
      "metadata": {
        "id": "G3OYfkq-02Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recent_data = yf.download(\"BRK-B\", period=\"5d\")\n",
        "recent_data"
      ],
      "metadata": {
        "id": "cyPHYUU_En8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all_stock_data.to_csv('/content/drive/MyDrive/Upwork/Stock Data Analysis/all_stock_data.csv', index=False)"
      ],
      "metadata": {
        "id": "scr67xhqPjFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tickers"
      ],
      "metadata": {
        "id": "fondqaBx1_se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = yf.download('AAPL', start=start_date, end=end_date, auto_adjust=True)[['Close']]"
      ],
      "metadata": {
        "id": "iM3E8Xih2DId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "70EJYpo02HqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yfinance_adj_close.head()"
      ],
      "metadata": {
        "id": "p-_nx8UW2051"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: change stock ticker BRK.B to BRK-B in df\n",
        "\n",
        "transactions['Stock Ticker'] = transactions['Stock Ticker'].replace('BRK.B', 'BRK-B')\n",
        "\n",
        "\n",
        "\n",
        "# Clean and process tickers and dates\n",
        "#transactions['Stock Ticker'] = transactions['Stock Ticker'].str.replace('$', '').str.strip()\n",
        "transactions['Traded'] = pd.to_datetime(transactions['Traded']).dt.strftime('%Y-%m-%d')\n",
        "transactions['Stock Ticker'] = transactions['Stock Ticker'].astype(str) # Convert 'Stock Ticker' column to string type\n",
        "\n",
        "\n",
        "# Add columns for buy and sell prices\n",
        "transactions['Transaction Price'] = transactions.apply(\n",
        "    lambda row: get_stock_price(row['Stock Ticker'], row['Traded']), axis=1)\n",
        "\n",
        "# Save the updated data with transaction prices\n",
        "transactions.to_csv('transactions_with_prices.csv', index=False)\n",
        "transactions.head()"
      ],
      "metadata": {
        "id": "M2ZWqxv2HPfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file in your Google Drive\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Upwork/Stock Data Analysis/transaction_scraped.csv', index=False)"
      ],
      "metadata": {
        "id": "B76EJDSCeT6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "J5c9MF8-cbZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for numerical columns\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "PpGx5vwGdKll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "id": "QF4ogeNIytkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "vpNZqhsuyuwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "jnNdMkwOcci6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "4VAgMMl5zH85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the DataFrame\n",
        "df.shape"
      ],
      "metadata": {
        "id": "jIYp10EydG3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column names\n",
        "df.columns"
      ],
      "metadata": {
        "id": "OOfFeUMudN38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data types of each column\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "sncgNwk0dOkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of non-null values in each column\n",
        "df.count()"
      ],
      "metadata": {
        "id": "XWWbUzHGdPPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "Oo9PT99n0JAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for all columns, including categorical ones\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "JAXydUzidRtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "UIu4SipicI76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values in the 'Transaction' column\n",
        "df['Transaction'].unique()"
      ],
      "metadata": {
        "id": "HUoXa_cldFji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value counts for the 'Transaction' column\n",
        "df['Transaction'].value_counts()"
      ],
      "metadata": {
        "id": "dp-TVk4LdE70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame for purchase transactions\n",
        "purchase_df = df[df['Transaction'] == 'Purchase']"
      ],
      "metadata": {
        "id": "q4B2TUJkdEXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by 'Politician' and count the number of transactions\n",
        "transactions_by_politician = df.groupby('Politician')['Transaction'].count()"
      ],
      "metadata": {
        "id": "N0TIa3t4dDyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the transactions by politician in descending order\n",
        "transactions_by_politician_sorted = transactions_by_politician.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "fBLB_Vy-dDI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by 'Stock Ticker' and calculate the average amount\n",
        "average_amount_by_stock = df.groupby('Stock Ticker')['Amount'].mean()"
      ],
      "metadata": {
        "id": "1bAL3WujdCeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the average amounts by stock in descending order\n",
        "average_amount_by_stock_sorted = average_amount_by_stock.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "tiAbgq6ndBxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame for transactions related to a specific stock\n",
        "specific_stock_df = df[df['Stock Ticker'] == 'AAPL']"
      ],
      "metadata": {
        "id": "5okZb9xpdBJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlPs-H3CdAiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the time difference between disclosure and trade dates\n",
        "df['Disclosure_Trade_Difference'] = (df['Disclosed'] - df['Traded']).dt.days"
      ],
      "metadata": {
        "id": "ZrioHfn8dAKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of disclosure-trade time differences\n",
        "df['Disclosure_Trade_Difference'].describe()"
      ],
      "metadata": {
        "id": "uV4J3yqPc94v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Trade Date'] = df['Traded'].dt.date"
      ],
      "metadata": {
        "id": "9-gJ99eK1Msr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qKfYZ4De69Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROI Calculation"
      ],
      "metadata": {
        "id": "4Zh2UUG06-kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Data for ROI calculation\n",
        "df_roi = df[df['Politician'] == 'Josh Gottheimer']"
      ],
      "metadata": {
        "id": "tO3JItrQBHgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_roi"
      ],
      "metadata": {
        "id": "2MEHtu0ECEmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Stock Ticker' and 'Transaction' and count the occurrences\n",
        "transaction_counts = df_roi.groupby(['Stock Ticker', 'Transaction']).size().reset_index(name='Count')\n",
        "\n",
        "# Display the result\n",
        "print(transaction_counts)\n"
      ],
      "metadata": {
        "id": "oSlY-v1kuvOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "Lm3ONJTcxD_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "vCLc9WWeB54h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prices"
      ],
      "metadata": {
        "id": "yvmEBE1dDVf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Function to get the price of a stock on a specific date\n",
        "def get_price_on_date(stock_ticker, date, prices_df):\n",
        "    try:\n",
        "        price_row = prices_df[(prices_df['Stock_Ticker'] == stock_ticker) & (prices_df['Traded'] == date)]\n",
        "        if not price_row.empty:\n",
        "            return price_row.iloc[0]['Price']\n",
        "        else:\n",
        "            return None\n",
        "    except IndexError:\n",
        "        return None\n",
        "\n",
        "# Function to calculate the ROI\n",
        "def calculate_roi(purchase_price, sell_price):\n",
        "    return ((sell_price - purchase_price) / purchase_price) * 100\n",
        "\n",
        "# Filter by a specific politician\n",
        "politician_name = 'Politician1'\n",
        "df_filtered = df_roi[df_roi['Politician'] == politician_name]\n",
        "\n",
        "# Today's date and earliest available date\n",
        "today_date = all_prices_df['Traded'].max()\n",
        "earliest_date = all_prices_df['Traded'].min()\n",
        "\n",
        "# Results storage\n",
        "roi_results = []\n",
        "\n",
        "# Group by Stock Ticker\n",
        "grouped = df_filtered.groupby(['Stock_Ticker'])\n",
        "\n",
        "for stock_ticker, group in grouped:\n",
        "    purchases = group[group['Transaction'] == 'Purchase']\n",
        "    sales = group[group['Transaction'] == 'Sale']\n",
        "\n",
        "    if not purchases.empty and not sales.empty:\n",
        "        # Match purchases and sales\n",
        "        for (idx_p, purchase), (idx_s, sale) in zip(purchases.iterrows(), sales.iterrows()):\n",
        "            buy_price = get_price_on_date(stock_ticker, pd.to_datetime(purchase['Traded']), all_prices_df)\n",
        "            sell_price = get_price_on_date(stock_ticker, pd.to_datetime(sale['Traded']), all_prices_df)\n",
        "            if buy_price is not None and sell_price is not None:\n",
        "                roi = calculate_roi(buy_price, sell_price)\n",
        "                roi_results.append({'Politician': politician_name, 'Stock_Ticker': stock_ticker, 'ROI': roi, 'Buy_Date': purchase['Traded'], 'Sell_Date': sale['Traded']})\n",
        "\n",
        "    elif not purchases.empty:\n",
        "        # Calculate ROI for buys with today's price\n",
        "        today_price = get_price_on_date(stock_ticker, today_date, all_prices_df)\n",
        "        for _, purchase in purchases.iterrows():\n",
        "            buy_price = get_price_on_date(stock_ticker, pd.to_datetime(purchase['Traded']), all_prices_df)\n",
        "            if buy_price is not None and today_price is not None:\n",
        "                roi = calculate_roi(buy_price, today_price)\n",
        "                roi_results.append({'Politician': politician_name, 'Stock_Ticker': stock_ticker, 'ROI': roi, 'Buy_Date': purchase['Traded'], 'Sell_Date': today_date})\n",
        "\n",
        "    elif not sales.empty:\n",
        "        # Calculate ROI for sales with earliest available price\n",
        "        earliest_price = get_price_on_date(stock_ticker, earliest_date, all_prices_df)\n",
        "        for _, sale in sales.iterrows():\n",
        "            sell_price = get_price_on_date(stock_ticker, pd.to_datetime(sale['Traded']), all_prices_df)\n",
        "            if earliest_price is not None and sell_price is not None:\n",
        "                roi = calculate_roi(earliest_price, sell_price)\n",
        "                roi_results.append({'Politician': politician_name, 'Stock_Ticker': stock_ticker, 'ROI': roi, 'Buy_Date': earliest_date, 'Sell_Date': sale['Traded']})\n",
        "\n",
        "# Create a DataFrame with the ROI results\n",
        "roi_df = pd.DataFrame(roi_results)\n",
        "\n",
        "# Calculate summary statistics\n",
        "total_roi = roi_df['ROI'].sum()\n",
        "highest_roi = roi_df['ROI'].max()\n",
        "lowest_roi = roi_df['ROI'].min()\n",
        "\n",
        "print(\"Total ROI: {:.2f}%\".format(total_roi))\n",
        "print(\"Highest ROI: {:.2f}%\".format(highest_roi))\n",
        "print(\"Lowest ROI: {:.2f}%\".format(lowest_roi))\n",
        "print(\"\\nResults DataFrame:\")\n",
        "print(roi_df)\n"
      ],
      "metadata": {
        "id": "uiInzRHyxFF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_roi.nunique()"
      ],
      "metadata": {
        "id": "iIOdLR2vCXR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yahoo_stock_roi_name = df_roi['Stock Ticker'].unique()"
      ],
      "metadata": {
        "id": "0lgpSlhYCsEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yahoo_stock_roi_name"
      ],
      "metadata": {
        "id": "jhM-NlAsEhgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "\n",
        "# Function to calculate ROI\n",
        "def calculate_roi(trades, historical_prices):\n",
        "    roi_data = []\n",
        "    for _, trade in trades.iterrows():\n",
        "        symbol = trade['Stock Ticker']\n",
        "        transaction_type = trade['Transaction']\n",
        "        transaction_date = trade['Transaction Date']\n",
        "        amount = float(trade['Amount'].replace('$', '').replace(',', ''))\n",
        "\n",
        "        # Complete trade logic\n",
        "        if transaction_type == 'Buy':\n",
        "            buy_price = historical_prices[symbol].loc[transaction_date]['Close']\n",
        "            sell_price = historical_prices[symbol].iloc[-1]['Close']  # Current price\n",
        "            roi = (sell_price - buy_price) / buy_price * 100\n",
        "\n",
        "        elif transaction_type == 'Sale':\n",
        "            sell_price = historical_prices[symbol].loc[transaction_date]['Close']\n",
        "            buy_price = historical_prices[symbol].iloc[0]['Close']  # Earliest price\n",
        "            roi = (sell_price - buy_price) / buy_price * 100\n",
        "\n",
        "        roi_data.append({\n",
        "            'Politician': trade['Politician'],\n",
        "            'Stock Ticker': symbol,\n",
        "            'Transaction Type': transaction_type,\n",
        "            'Transaction Date': transaction_date,\n",
        "            'ROI': roi\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(roi_data)\n",
        "\n",
        "# Main function to execute the workflow\n",
        "def main():\n",
        "    trades = df_roi\n",
        "    unique_symbols = trades['Stock Ticker'].unique()\n",
        "    historical_prices = {symbol: get_historical_prices(symbol) for symbol in unique_symbols}\n",
        "    roi_data = calculate_roi(trades, historical_prices)\n",
        "    roi_data.to_csv('congress_trading_roi.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "v6P34Hgl1Num"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YFinance Data Scrape & Merge\n"
      ],
      "metadata": {
        "id": "C34xUHvl5xVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True)[['Close']]"
      ],
      "metadata": {
        "id": "yVclLu2RE88L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming 'transactions' is your DataFrame with a 'Stock Ticker' column\n",
        "\n",
        "\n",
        "########\n",
        "#######unique_tickers = transactions['Stock Ticker'].str.replace('$', '').str.strip().unique()\n",
        "\n",
        "unique_tickers = yahoo_stock_roi_name[:10]\n",
        "# Fetch historical prices for all unique tickers\n",
        "start_date = \"2021-01-01\"\n",
        "end_date = pd.Timestamp.today().strftime('%Y-%m-%d')  # Today's date\n",
        "\n",
        "# Initialize a dictionary to store the data\n",
        "yfinance_adj_close = {}\n",
        "\n",
        "# Use tqdm to display a progress bar\n",
        "for ticker in tqdm(unique_tickers, desc=\"Fetching stock data\"):\n",
        "    try:\n",
        "        # Download the adjusted close price\n",
        "        data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True)[['Close']]\n",
        "        yfinance_adj_close[ticker] = data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {ticker}: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nwNXV4HcNAfI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "AyYgUGpKGAuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aapl_data = yfinance_adj_close['AAPL']\n"
      ],
      "metadata": {
        "id": "kBwOpc4XkBWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aapl_data"
      ],
      "metadata": {
        "id": "YSeQGhJBkDMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yfinance_adj_close"
      ],
      "metadata": {
        "id": "H0QQvsk5jtKP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = pd.concat(yfinance_adj_close, axis=1)\n",
        "combined_data.columns = combined_data.columns.droplevel(0)  # Dropping the top-level column index\n",
        "\n",
        "# Save the combined data to a single CSV file\n",
        "combined_data.to_csv('combined_stock_data.csv', index=True)"
      ],
      "metadata": {
        "id": "L6hjPvOjjqEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty DataFrame to store all yfinance data\n",
        "all_data = pd.DataFrame()\n",
        "\n",
        "# Normalize and clean the data if necessary\n",
        "#transactions['Stock Ticker'] = transactions['Stock Ticker'].str.replace('$', '').str.strip()\n",
        "transactions['Traded'] = pd.to_datetime(transactions['Traded'])\n",
        "\n",
        "# Reset index to make 'Date' a column\n",
        "all_data.reset_index(inplace=True)\n",
        "yfinance_adj_close.rename(columns={'Date': 'Traded'}, inplace=True)\n",
        "\n",
        "# Merge transactions with stock prices\n",
        "merged_data = pd.merge(transactions, v, on=['Stock Ticker', 'Traded'], how='left')\n",
        "\n",
        "# Save the merged data to a new CSV\n",
        "merged_data.to_csv(\"merged_transactions_and_prices.csv\", index=False)\n",
        "\n",
        "merged_data.head()"
      ],
      "metadata": {
        "id": "r5EUYjhV6Es0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions.head()"
      ],
      "metadata": {
        "id": "o8kK9Tse7g--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions.nunique()"
      ],
      "metadata": {
        "id": "4xOVWUqC-e82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prices.sample(10)"
      ],
      "metadata": {
        "id": "suMUOHc7_wB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prices.Stock_Ticker"
      ],
      "metadata": {
        "id": "euXRsPL0_y8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prices.nunique()"
      ],
      "metadata": {
        "id": "OAl4dTHK94cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming yfinance_adj_close is a dictionary where keys are tickers and values are DataFrames\n",
        "# containing 'Close' prices and indexed by date.\n",
        "\n",
        "# List to hold individual DataFrames with a 'Traded' date column and a 'Stock_Ticker' column\n",
        "dataframes = []\n",
        "\n",
        "for ticker, df in yfinance_adj_close.items():\n",
        "    # Reset the index to convert the Date index into a column\n",
        "    df_reset = df.reset_index()\n",
        "    df_reset.rename(columns={'index': 'Traded', 'Close': 'Price'}, inplace=True)\n",
        "    df_reset['Stock_Ticker'] = ticker\n",
        "    dataframes.append(df_reset)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "all_prices = pd.concat(dataframes, axis=0, ignore_index=True)\n",
        "\n",
        "# Ensure 'Traded' column is treated as datetime\n",
        "all_prices['Traded'] = pd.to_datetime(all_prices['Traded'], errors='coerce')\n",
        "\n",
        "# Checking for any NaT values in 'Traded' after conversion\n",
        "if all_prices['Traded'].isnull().any():\n",
        "    print(\"Warning: Some 'Traded' dates could not be converted to datetime.\")\n",
        "\n",
        "# Print the first few rows to check the result\n",
        "print(all_prices.head())\n"
      ],
      "metadata": {
        "id": "F8AC6N4J9dy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example structure of yfinance_adj_close\n",
        "# yfinance_adj_close = {\n",
        "#     'MSFT': DataFrame, 'AAPL': DataFrame, ...\n",
        "# }\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "all_prices = pd.concat(\n",
        "    [df.assign(Stock_Ticker=ticker) for ticker, df in yfinance_adj_close.items()],\n",
        "    axis=0\n",
        ").reset_index().rename(columns={'index': 'Traded', 'Close': 'Price'})\n",
        "\n",
        "# Ensure 'Traded' is datetime\n",
        "all_prices['Traded'] = pd.to_datetime(all_prices['Traded'])\n"
      ],
      "metadata": {
        "id": "-SDSMrNM7R2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the transaction data with stock prices on 'Stock Ticker' and 'Traded'\n",
        "merged_data = pd.merge(transactions, all_prices, left_on=['Stock Ticker', 'Traded'], right_on=['Stock_Ticker', 'Traded'], how='left')\n",
        "\n",
        "# Save the merged data to a new CSV file\n",
        "merged_data.to_csv(\"merged_transactions_and_prices.csv\", index=False)\n",
        "\n",
        "# Display the first few rows of the merged DataFrame\n",
        "print(merged_data.head())\n"
      ],
      "metadata": {
        "id": "ZMme3liy81cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yfinance_adj_close"
      ],
      "metadata": {
        "collapsed": true,
        "id": "viqt7Xr0GcbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming 'transactions' is your DataFrame with a 'Stock Ticker' column\n",
        "unique_tickers = transactions['Stock Ticker'].str.replace('$', '').str.strip().unique()[:10]\n",
        "\n",
        "# Fetch historical prices for all unique tickers\n",
        "start_date = \"2021-01-01\"\n",
        "end_date = pd.Timestamp.today().strftime('%Y-%m-%d')  # Today's date\n",
        "\n",
        "# Initialize a dictionary to store the data\n",
        "yfinance_adj_close = {}\n",
        "\n",
        "# Use tqdm to display a progress bar\n",
        "for ticker in tqdm(unique_tickers, desc=\"Fetching stock data\"):\n",
        "    try:\n",
        "        # Download the adjusted close price\n",
        "        data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True)[['Close']]\n",
        "        yfinance_adj_close[ticker] = data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {ticker}: {e}\")\n",
        "\n",
        "# Example to check the data for a specific ticker\n",
        "for ticker, data in yfinance_adj_close.items():\n",
        "    print(f\"Data for {ticker}:\")\n",
        "    print(data.head())\n"
      ],
      "metadata": {
        "id": "P5ZSMOGU7Y89",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yfinance_adj_close.items()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3Vz4EZ9MHREV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dictionary structure for yfinance_adj_close\n",
        "# yfinance_adj_close = {\n",
        "#     'AAPL': DataFrame with date index and 'Close' price column,\n",
        "#     'MSFT': DataFrame with date index and 'Close' price column,\n",
        "#     # ... other tickers\n",
        "# }\n",
        "\n",
        "# List to store individual DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Iterate over each ticker and its corresponding DataFrame\n",
        "for ticker, df in yfinance_adj_close.items():\n",
        "    # Reset index to turn the date index into a column\n",
        "    df_reset = df.reset_index()\n",
        "    df_reset.rename(columns={'Date': 'Traded', 'Close': 'Price'}, inplace=True)\n",
        "    df_reset['Stock_Ticker'] = ticker\n",
        "    dataframes.append(df_reset)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "all_prices = pd.concat(dataframes, axis=0, ignore_index=True)\n",
        "\n",
        "# Convert 'Traded' to datetime format\n",
        "all_prices['Traded'] = pd.to_datetime(all_prices['Traded'], errors='coerce')\n",
        "\n",
        "# Display the first few rows to verify the result\n",
        "print(all_prices.head())\n"
      ],
      "metadata": {
        "id": "ySORfix7G3nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prices"
      ],
      "metadata": {
        "id": "dq-_h5m3G6C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the DataFrame with 'Traded' as index and 'Stock_Ticker' as columns\n",
        "pivot_df = all_prices.pivot(index='Traded', columns='Stock_Ticker', values='Price')\n",
        "\n",
        "# Display the first few rows of the pivoted DataFrame\n",
        "print(pivot_df.head())\n"
      ],
      "metadata": {
        "id": "vtesAhKsG6-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df"
      ],
      "metadata": {
        "id": "fRW_LX7oHc0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCI63JK-HdbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge df_roi and pivot_stock_prices"
      ],
      "metadata": {
        "id": "7oBEzDftIwFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_roi"
      ],
      "metadata": {
        "id": "7Mo1_DesI3kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_roi"
      ],
      "metadata": {
        "id": "uB7QrLBoJH99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df.head()"
      ],
      "metadata": {
        "id": "SAMwKkBFJQJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df.reset_index()"
      ],
      "metadata": {
        "id": "p0IDs0X5Jc3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df"
      ],
      "metadata": {
        "id": "sXLdZen7JlBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df.head()"
      ],
      "metadata": {
        "id": "Ov2iOuMdJsGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df_reset"
      ],
      "metadata": {
        "id": "wIsqYsstJuno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_roi.info()"
      ],
      "metadata": {
        "id": "hDxjZzdvJ2DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df.head()"
      ],
      "metadata": {
        "id": "ngjHKZlZJ9j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prices.info()"
      ],
      "metadata": {
        "id": "LhKca-YTKwV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exRApfBiK6dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure 'Stock Ticker' is a string in df_roi\n",
        "df_roi['Stock Ticker'] = df_roi['Stock Ticker'].astype(str)\n",
        "\n",
        "\"\"\"# Reset index in pivot_df to include 'Traded' (Date) as a column\n",
        "pivot_df_reset = pivot_df.reset_index()\n",
        "pivot_df_reset['Date'] = pivot_df_reset['Traded']\n",
        "#df_roi = df_roi.reset_index(drop=False)\n",
        "pivot_df_reset['Date'] = pd.to_datetime(pivot_df_reset['Date'], format='%Y-%m-%d')\"\"\"\n",
        "\n",
        "# Merge df_roi with pivot_df_reset on 'Traded' and 'Stock Ticker'\n",
        "merged_df = pd.merge(df_roi, all_prices, left_on=['Traded', 'Stock Ticker'], right_on=['Traded', 'Stock_Ticker'], how='left')\n",
        "\n",
        "# Drop the redundant 'Date' column if needed\n",
        "#merged_df.drop(columns=['Date'], inplace=True)\n",
        "\n",
        "# Display the merged DataFrame\n",
        "merged_df.head()\n"
      ],
      "metadata": {
        "id": "ectD308UI1OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the specified columns\n",
        "merged_df = merged_df.drop(columns=['Politician Profile', 'Description', 'House Information', 'Stock', 'Industry'])\n",
        "#merged_df = merged_df.dropna()"
      ],
      "metadata": {
        "id": "H34Iac-oLHf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deneme_df = merged_df[merged_df['Stock_Ticker'] == \"AAPL\"]"
      ],
      "metadata": {
        "id": "Mwdl0Aw3Lpyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deneme_df.head()"
      ],
      "metadata": {
        "id": "YAJ09AvMMkG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to calculate ROI\n",
        "def calculate_roi(buy_price, sell_price):\n",
        "    return ((sell_price - buy_price) / buy_price) * 100\n",
        "\n",
        "# Define a function to calculate the highest ROI\n",
        "def highest_roi_for_stock(stock_df):\n",
        "    buys = stock_df[stock_df['Transaction'] == 'Purchase']\n",
        "    sells = stock_df[stock_df['Transaction'] == 'Sale']\n",
        "\n",
        "    if not buys.empty and not sells.empty:\n",
        "        # Both buy and sell trades present\n",
        "        max_roi = float('-inf')\n",
        "        for _, buy_row in buys.iterrows():\n",
        "            for _, sell_row in sells.iterrows():\n",
        "                roi = calculate_roi(buy_row['Price'], sell_row['Price'])\n",
        "                if roi > max_roi:\n",
        "                    max_roi = roi\n",
        "        return max_roi\n",
        "\n",
        "    elif not buys.empty:\n",
        "        # Only buy trades are present\n",
        "        latest_price = buys['Price'].max()\n",
        "        today_price = df[df['Traded'] == df['Traded'].max()]['Price'].values[0]\n",
        "        roi = calculate_roi(latest_price, today_price)\n",
        "        return roi\n",
        "\n",
        "    elif not sells.empty:\n",
        "        # Only sell trades are present\n",
        "        earliest_price = df[df['Traded'] == df['Traded'].min()]['Price'].values[0]\n",
        "        max_sell_price = sells['Price'].max()\n",
        "        roi = calculate_roi(earliest_price, max_sell_price)\n",
        "        return roi\n",
        "\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Calculate highest ROI for each stock ticker\n",
        "results = []\n",
        "for ticker in df['Stock Ticker'].unique():\n",
        "    stock_df = df[df['Stock Ticker'] == ticker]\n",
        "    roi = highest_roi_for_stock(stock_df)\n",
        "    results.append({'Stock Ticker': ticker, 'Highest ROI': roi})\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "66pjSDpWTOpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_prices"
      ],
      "metadata": {
        "id": "RGAtGVp2UbwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "il21tt39VySw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T9h1EgtNUYA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_price_on_date(stock_ticker, date, all_prices_df):\n",
        "    # Find the price on the given date for the specified stock ticker\n",
        "    price_df = all_prices_df[(all_prices_df['Stock_Ticker'] == stock_ticker) & (all_prices_df['Traded'] == date)]\n",
        "    if not price_df.empty:\n",
        "        return price_df['Price'].values[0]\n",
        "    return None\n",
        "\n",
        "def calculate_roi(purchase_amount, purchase_price, sell_amount, sell_price):\n",
        "    # Calculate ROI as a percentage\n",
        "    return ((sell_price - purchase_price) / purchase_price) * 100\n",
        "\n",
        "def highest_roi(politician_df, all_prices_df):\n",
        "    results = []\n",
        "\n",
        "    # Group by Stock_Ticker and Politician\n",
        "    grouped = politician_df.groupby(['Stock_Ticker', 'Politician'])\n",
        "\n",
        "    for (stock_ticker, politician), trades in grouped:\n",
        "        buy_trades = trades[trades['Transaction'] == 'Purchase']\n",
        "        sell_trades = trades[trades['Transaction'] == 'Sale']\n",
        "\n",
        "        buy_dates = buy_trades['Traded'].tolist()\n",
        "        sell_dates = sell_trades['Traded'].tolist()\n",
        "\n",
        "        if buy_trades.empty and not sell_trades.empty:\n",
        "            # Scenario 3: Only sell trades - Assume buying at the earliest date\n",
        "            earliest_date = all_prices_df['Traded'].min()\n",
        "            earliest_price = get_price_on_date(stock_ticker, earliest_date, all_prices_df)\n",
        "            if earliest_price is not None:\n",
        "                for _, sell_trade in sell_trades.iterrows():\n",
        "                    sell_price = get_price_on_date(stock_ticker, sell_trade['Traded'], all_prices_df)\n",
        "                    if sell_price is not None:\n",
        "                        roi = calculate_roi(sell_trade['Amount'], earliest_price, sell_trade['Amount'], sell_price)\n",
        "                        results.append({'Politician': politician, 'Stock_Ticker': stock_ticker, 'ROI': roi})\n",
        "\n",
        "        elif not buy_trades.empty and sell_trades.empty:\n",
        "            # Scenario 2: Only buy trades - Assume selling at today's price\n",
        "            today_date = all_prices_df['Traded'].max()\n",
        "            today_price = get_price_on_date(stock_ticker, today_date, all_prices_df)\n",
        "            if today_price is not None:\n",
        "                for _, buy_trade in buy_trades.iterrows():\n",
        "                    buy_price = get_price_on_date(stock_ticker, buy_trade['Traded'], all_prices_df)\n",
        "                    if buy_price is not None:\n",
        "                        roi = calculate_roi(buy_trade['Amount'], buy_price, buy_trade['Amount'], today_price)\n",
        "                        results.append({'Politician': politician, 'Stock_Ticker': stock_ticker, 'ROI': roi})\n",
        "\n",
        "        elif not buy_trades.empty and not sell_trades.empty:\n",
        "            # Scenario 1: Both buy and sell trades - Match the buys and sells\n",
        "            for _, buy_trade in buy_trades.iterrows():\n",
        "                buy_price = get_price_on_date(stock_ticker, buy_trade['Traded'], all_prices_df)\n",
        "                if buy_price is not None:\n",
        "                    # Match with a corresponding sell trade\n",
        "                    for _, sell_trade in sell_trades.iterrows():\n",
        "                        sell_price = get_price_on_date(stock_ticker, sell_trade['Traded'], all_prices_df)\n",
        "                        if sell_price is not None:\n",
        "                            roi = calculate_roi(buy_trade['Amount'], buy_price, sell_trade['Amount'], sell_price)\n",
        "                            results.append({'Politician': politician, 'Stock_Ticker': stock_ticker, 'ROI': roi})\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    return results_df\n"
      ],
      "metadata": {
        "id": "t6lL6x9lYJ8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming deneme_df and all_prices_df are already defined and populated\n",
        "highest_roi(deneme_df, all_prices)"
      ],
      "metadata": {
        "id": "9te9N5mZYqIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already defined and computed results_df\n",
        "results_df = highest_roi(deneme_df, all_prices)\n",
        "\n",
        "# Calculate summary statistics\n",
        "total_roi = results_df['ROI'].sum()\n",
        "highest_roi = results_df['ROI'].max()\n",
        "lowest_roi = results_df['ROI'].min()\n",
        "\n",
        "# Print the results\n",
        "print(\"Total ROI: {:.2f}%\".format(total_roi))\n",
        "print(\"Highest ROI: {:.2f}%\".format(highest_roi))\n",
        "print(\"Lowest ROI: {:.2f}%\".format(lowest_roi))\n",
        "print(\"\\nResults DataFrame:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "DS0ubwbuY2tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(deneme_df)"
      ],
      "metadata": {
        "id": "bfdrUU4cgGGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deneme_df.head(50)"
      ],
      "metadata": {
        "id": "wUVHve4Thedx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "4T5vRIckfelP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}